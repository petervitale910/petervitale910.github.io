[
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "All my favorite resources",
    "section": "",
    "text": "this is an h1 element\n\n\nthis is an h1 element with the title class\n\n\nthis paragraph is butterscotch\n\n\nthis paragraph is centered\n\n\nthis paragraph is centered and butterscotch\n\n\nHere’s where I’m describing something fun that I enjoy doing\n\nThis\nis\nall\nbutterscotch\n\n\nThis\nis\nall\ncentered"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "I am currently a student who works"
  },
  {
    "objectID": "about.html#what-i-do-for-work",
    "href": "about.html#what-i-do-for-work",
    "title": "About",
    "section": "",
    "text": "I am currently a student who works"
  },
  {
    "objectID": "about.html#what-i-do-for-fun",
    "href": "about.html#what-i-do-for-fun",
    "title": "About",
    "section": "What I do for fun",
    "text": "What I do for fun\nLeague of Legends; give the ppl what they want."
  },
  {
    "objectID": "posts/sf_bay_catches/index.html",
    "href": "posts/sf_bay_catches/index.html",
    "title": "San Fransisco Bay Catch Dynamics",
    "section": "",
    "text": "Wooldridge (2020)\n\n\nThe San Francisco Bay is a large estuarine bay in Northern California which spans 60 miles (Britannica, n.d.). The San Francisco Estuary is the largest estuary in California, with rivers from the ridgeline of the Sierra Nevada mountains leading to the strait of the Golden Gate, including almost 60,000 square miles and nearly 40% of California (Partnership, n.d.). As of 2002, San Francisco Bay sustains nearly 500 species of fish, invertebrates, birds, mammals, insects and amphibians. It is an essential resting place, feeding area, and wintering ground for millions of birds on the Pacific Flyway. Nearly half of the state’s waterfowl and shorebirds and two-third of the state’s salmon pass through the Bay during their migrations (Conservation and Commission 2002).\nIn recent years harmful algal blooms (HABs) have decimated many populations in the bay. HABs are becoming more frequent and more intense across California as waters warm. Decreased flows from inland rivers and streams, and increased concentrations of nutrients and other land-based pollutants additionally exacerbate the growth of algae and cyanotoxins (Council 2022).\nWhen monitoring the bay, it is often difficult to monitor less populated species to the extent of more frequent species. To combat this in this project I will be comparing populations of Northern Anchovy, the most populous species in the bay, to that of other more niche species.\n\nDAG\nThis analysis is predicated on the same environmental factors effecting Northern Anchovies and other species at similar levels. This leads to a DAG which looks like this:\n\n\nCode\ndag &lt;- dagitty::dagitty('dag {\nbb=\"0,0,1,1\"\n\"Bay Region\" [pos=\"0.375,0.496\"]\n\"Environmental Variables (EG. Toxic algal bloom)\" [pos=\"0.378,0.222\"]\n\"Northern Anchovy Population\" [pos=\"0.277,0.343\"]\n\"Sp Population\" [pos=\"0.495,0.341\"]\n\"Bay Region\" -&gt; \"Environmental Variables (EG. Toxic algal bloom)\"\n\"Bay Region\" -&gt; \"Northern Anchovy Population\"\n\"Bay Region\" -&gt; \"Sp Population\"\n\"Environmental Variables (EG. Toxic algal bloom)\" -&gt; \"Northern Anchovy Population\"\n\"Environmental Variables (EG. Toxic algal bloom)\" -&gt; \"Sp Population\"\n}')\n\nplot(dagitty::graphLayout(dag))\n\n\n\n\n\n\n\n\n\n\n\nImport packages\n\n\nCode\npacman::p_load('tidyverse', \n               'here',\n               'janitor',\n               'indicspecies',\n               'MASS',\n               'ggthemes',\n               'stargazer',\n               'broom',\n               'knitr',\n               'kableExtra')\n\n\n\n\nImport and clean data\nFirst we import data which was requested from (Institute n.d.)\n\n\nCode\n# Raw catch data\ncatch_raw &lt;- read_csv(here::here('posts', 'sf_bay_catches', 'data', 'catch_9218.csv'))\n\n# For easy reference we also import species key \nspecies_key &lt;- read_csv(here::here('posts', 'sf_bay_catches','data', 'species_key.csv'), col_names = FALSE)\n\n\nNow we can clean up the messy dataset and make a functional species key\n\n\nCode\n# The species key has some very difficult first columns so we need to restrict it down to just species code and name\nspecies_key_clean &lt;- species_key[c(4,5),3:125] %&gt;% \n  row_to_names(row_number = 1) %&gt;% \n  clean_names() %&gt;% \n  remove_empty(which = \"rows\") %&gt;% \n  pivot_longer(cols = everything(),names_to = 'species_code', values_to = 'species_name')%&gt;% \n  mutate(species_code = str_to_upper(species_code),\n                                     species_name = str_to_title(str_to_lower(species_name)))\n\nspecies_key_clean\n\n\n# A tibble: 123 × 2\n   species_code species_name          \n   &lt;chr&gt;        &lt;chr&gt;                 \n 1 AG           Arrow Goby            \n 2 AS           American Shad         \n 3 BBC          Brown Bullhead Catfish\n 4 BG           Bay Goby              \n 5 BHS          Bonyhead Sculpin      \n 6 BOC          Bocaccio Rockfish     \n 7 BP           Black Perch           \n 8 BPF          Bay Pipefish          \n 9 BR           Bat Ray               \n10 BRF          Bolinas Rockfish      \n# ℹ 113 more rows\n\n\n\n\nCode\n# The catch data is much cleaner, all we need is a quick clean names\ncatch_clean &lt;- catch_raw %&gt;% \n  clean_names()\n\ncatch_clean$species_code[is.na(catch_clean$species_code)] &lt;- 'NA'\n\nhead(catch_clean)\n\n\n# A tibble: 6 × 37\n  catch_info_trawl_id species_code  size class number sex   trawl_map_trawl_id\n                &lt;dbl&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;              &lt;dbl&gt;\n1                  10 SSP              0    NA      1 &lt;NA&gt;                  10\n2                  10 SSP             90    NA      1 &lt;NA&gt;                  10\n3                  10 SSP             56    NA      1 &lt;NA&gt;                  10\n4                  10 NA              NA    NA     15 &lt;NA&gt;                  10\n5                  10 CH              NA    NA      4 &lt;NA&gt;                  10\n6                  10 BS             480    NA      1 F                     10\n# ℹ 30 more variables: locale &lt;chr&gt;, trawl_map_training_trawl &lt;lgl&gt;,\n#   trawl_map_data_audit &lt;lgl&gt;, expr1 &lt;dbl&gt;, expr2 &lt;dbl&gt;,\n#   trawl_info_trawl_id &lt;dbl&gt;, hydro_id &lt;dbl&gt;, scientists &lt;chr&gt;, intern &lt;chr&gt;,\n#   date &lt;chr&gt;, school &lt;chr&gt;, trawl_time_begin &lt;dbl&gt;, trawl_time_end &lt;dbl&gt;,\n#   trawl_time_total &lt;dbl&gt;, depth_of_trawl &lt;dbl&gt;, tidal_current &lt;chr&gt;,\n#   last_slack_time &lt;dbl&gt;, last_slack_tide &lt;chr&gt;, last_slack_height &lt;dbl&gt;,\n#   sample_station &lt;chr&gt;, water_type &lt;chr&gt;, substrate &lt;chr&gt;, …\n\n\n\n\nPreliminary analysis: Top Species\nWe want to display the top 10 species caught by quantity to see what species we are catching most\n\n\nCode\ntop_10_catch &lt;- catch_clean %&gt;%\n  left_join(species_key_clean,\n            by = \"species_code\") %&gt;%\n  group_by(species_name) %&gt;%\n  summarise(total_catch = sum(number, na.rm = TRUE)) %&gt;%\n  arrange(desc(total_catch)) %&gt;%\n  slice_head(n = 10) \n\ntop_10_catch %&gt;% \nrename('Species Name' = species_name,\n             'Total Catch' = total_catch) %&gt;%  \nkable( format = \"html\", digits = 3,\n      caption = \"Top 10 Species Caught in the SF Bay\") %&gt;% \n  kable_styling(\n    bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n    full_width = FALSE,\n    position   = \"center\",\n    font_size  = 14\n  ) %&gt;% \n  row_spec(0, bold = TRUE, color = \"white\", background = \"#A0185A\") %&gt;%  # header\n  row_spec(1:nrow(top_10_catch), color = \"black\", background = \"#FFC4EB\")\n\n\n\n\nTop 10 Species Caught in the SF Bay\n\n\nSpecies Name\nTotal Catch\n\n\n\n\nNorthern Anchovy\n640618\n\n\nShiner Surfperch\n128489\n\n\nEnglish Sole\n84714\n\n\nStaghorn Sculpin\n27409\n\n\nPacific Herring\n25755\n\n\nSpeckled Sanddab\n15305\n\n\nCalifornia Halibut\n14069\n\n\nPlainfin Midshipman\n13662\n\n\nSanddab Sp.\n13231\n\n\nWhite Croaker\n11443\n\n\n\n\n\n\nIn this analysis we will take the most abundant species, Northern Anchovy, and compare it with indicator species from the different regions of the bay.\n\n\nPreliminary analysis: Indicator species\nIndicator species:\n\nreflect the biotic or abiotic state of the environment;\nprovide evidence for the impacts of environmental change; or\npredict the diversity of other species, taxa or communities within an area.\n\nBy comparing Anchovy population to that of indicator species, it may shed light on whether Anchovy population can be representative of the indicator.\nTo perform the indicator species analysis we will be using the function multipatt from the package indispecies. The function takes a group vector and a species matrix\n\n\nCode\nindicator &lt;- catch_clean %&gt;% \n  dplyr::select(catch_info_trawl_id, species_code, number, locale) %&gt;% \n  pivot_wider(names_from = species_code, values_from = number, values_fn = sum) %&gt;% \n  mutate(across(where(is.numeric), ~replace_na(., 0))) %&gt;% \n  filter(!locale == 'BLANK')\n\ngroup_vector &lt;- indicator$locale\n\nspecies_matrix &lt;- as.matrix(indicator[, -c(1, 2)])\n\n\nNow we can run the function multipatt to find indicator species values for our groups\n\n\nCode\nindval &lt;- multipatt(species_matrix, group_vector, \n                    control = how(nperm=999)) \n\n\n\n\nCode\n summary &lt;- summary(indval, alpha = .1) # Alpha is significance threshold \n\n\n\n Multilevel pattern analysis\n ---------------------------\n\n Association function: IndVal.g\n Significance level (alpha): 0.1\n\n Total number of species: 162\n Selected number of species: 51 \n Number of species associated to 1 group: 34 \n Number of species associated to 2 groups: 12 \n Number of species associated to 3 groups: 5 \n\n List of species associated to each combination: \n\n Group CENTRAL BAY  #sps.  14 \n     stat p.value   \nSSD 0.456   0.005 **\nCLF 0.217   0.048 * \nPOM 0.110   0.029 * \nps  0.066   0.049 * \nHH  0.065   0.068 . \nCRL 0.065   0.068 . \nOP  0.059   0.036 * \nJM  0.059   0.043 * \nBSC 0.050   0.037 * \nes  0.046   0.093 . \nIRL 0.042   0.032 * \nssd 0.042   0.023 * \nPB  0.039   0.100 . \nWOS 0.029   0.098 . \n\n Group SAN PABLO BAY  #sps.  4 \n     stat p.value  \nBR  0.449   0.014 *\nDT  0.328   0.032 *\nTS  0.277   0.029 *\nBSK 0.214   0.049 *\n\n Group SOUTH BAY  #sps.  2 \n     stat p.value  \nCT  0.308   0.063 .\nDSP 0.285   0.090 .\n\n Group SUISUN BAY  #sps.  14 \n     stat p.value    \nSB  0.880   0.001 ***\nSF  0.768   0.001 ***\nTFS 0.417   0.001 ***\nSST 0.303   0.001 ***\nDLS 0.204   0.004 ** \nBDG 0.204   0.008 ** \nTP  0.148   0.009 ** \nCC  0.129   0.004 ** \nBLP 0.129   0.003 ** \nCK  0.091   0.013 *  \nKS  0.091   0.028 *  \nDS  0.089   0.026 *  \nBBC 0.088   0.020 *  \nPL  0.086   0.048 *  \n\n Group CENTRAL BAY+SAN PABLO BAY  #sps.  6 \n     stat p.value    \nPMS 0.652   0.001 ***\nPH  0.535   0.003 ** \nBG  0.495   0.002 ** \nBPF 0.338   0.018 *  \nWSP 0.320   0.011 *  \nBHS 0.225   0.094 .  \n\n Group CENTRAL BAY+SOUTH BAY  #sps.  1 \n    stat p.value  \nSD 0.381    0.04 *\n\n Group CENTRAL BAY+SUISUN BAY  #sps.  1 \n    stat p.value  \nPS 0.267   0.049 *\n\n Group SAN PABLO BAY+SOUTH BAY  #sps.  1 \n    stat p.value  \nBS 0.343   0.038 *\n\n Group SAN PABLO BAY+SUISUN BAY  #sps.  2 \n     stat p.value    \nYG  0.574   0.002 ** \nLFS 0.538   0.001 ***\n\n Group SOUTH BAY+SUISUN BAY  #sps.  1 \n   stat p.value  \nUG 0.32   0.059 .\n\n Group CENTRAL BAY+SAN PABLO BAY+SOUTH BAY  #sps.  3 \n     stat p.value    \nNA  0.811   0.001 ***\nSSP 0.762   0.003 ** \nWC  0.385   0.031 *  \n\n Group CENTRAL BAY+SAN PABLO BAY+SUISUN BAY  #sps.  1 \n     stat p.value   \nPSD 0.527   0.002 **\n\n Group SAN PABLO BAY+SOUTH BAY+SUISUN BAY  #sps.  1 \n    stat p.value  \nLS 0.353   0.044 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 \n\n\nFrom the summary we can see that the top species for the four San Francisco Bay locales are:\nGroup CENTRAL BAY SSD: Speckled Sanddab\nGroup SAN PABLO BAY BR: Bat Ray\nGroup SOUTH BAY CT: California Tonguefish\nGroup SUISUN BAY SB: Striped Bass\nNext we are going to compare Northern Anchovy catches to these species using a hurdle model\n\n\nHurdle model and create function\nHurdle Models are a class of models for count data that help handle excess zeros and overdispersion, which fits our data to a T. It handles these by treating presence as a binary operator (present vs not present) and running a binomial(link = ‘logit’) model. The model also includes abundance, which analyzes count data using a negative binomial model.\nPresence: \\[\n\\begin{align}\n\\text{Presence} &\\sim Binomial(1, p) \\\\\nlogit(p) &= \\beta_0 + \\beta_1 \\text{NorthernAnchovyZ}* \\beta_2 \\text{inregion}\n\\end{align}\n\\] Abundance: \\[\n\\begin{align}\n\\text{Presence} &\\sim NegBin(\\lambda, \\theta) \\\\\nlog(\\lambda) &= \\beta_0 + \\beta_1 \\text{NorthernAnchovyZ}* \\beta_2 \\text{inregion}\n\\end{align}\n\\] We use the z-score transformed count of Northern Anchovy as it:\n\nHelps with numerical stability, especially in interaction terms\nIs useful when comparing effect sizes across variables on different scales\n\nBecause we are running and fitting this model four times, it sounds like I should make it into a function\n\n\nFunction\n\n\nCode\n#' predict indicator\n#'\n#' @param df\n#' Data frame used for analysis\n#' @param sp_code \n#' Species code (wrapped in '')\n#' @param region \n#' Locale (all capitals wrapped in '')\n#' @returns\n#' a list containing: \n#' stage1_summary \n#' stage2_summary \n#' stage1_pred \n#' stage2_pred\n#' combined_pred \n#' plot \n#' @export\n#'\n#' @examples\npredict_indicator &lt;- function(df, sp_code, region) {\n\n  species_name &lt;- species_key_clean %&gt;% \n    filter(species_code == sp_code) %&gt;% \n    pull(species_name) %&gt;% \n    make_clean_names()\n\n  catch_plot &lt;- df %&gt;% \n    filter(species_code == 'NA' | species_code == sp_code) %&gt;% \n    mutate(in_region = ifelse(locale == region, TRUE, FALSE)) %&gt;% \n    group_by(species_code, catch_info_trawl_id, in_region) %&gt;% \n    summarize(count = sum(number), .groups = \"drop\") %&gt;% \n    pivot_wider(names_from = species_code,\n                values_from = count) %&gt;% \n    set_names(c('trawl_id', 'in_region', 'northern_anchovy', species_name)) \n\n  catch_plot[is.na(catch_plot)] &lt;- 0\n\n  a &lt;- mean(catch_plot$northern_anchovy)\n  b &lt;- sd(catch_plot$northern_anchovy)\n\n  catch_plot &lt;- catch_plot %&gt;% \n    mutate(\n      northern_anchovy_z = (northern_anchovy - a) / b,\n      presence = ifelse(.data[[species_name]] &gt; 0, 1, 0),\n      abundance = ifelse(.data[[species_name]] &gt; 0, .data[[species_name]], NA)\n    )\n\n  # Stage 1 & 2 models\n  m1 &lt;- glm(presence ~ northern_anchovy_z * in_region, data = catch_plot, family = binomial(link = 'logit'))\n  m2 &lt;- glm.nb(abundance ~ northern_anchovy_z * in_region, data = catch_plot)\n\n  # Tidy outputs\n  m1_tidy &lt;- tidy(m1) %&gt;% mutate(model = \"Presence (Logit)\")\n  m2_tidy &lt;- tidy(m2) %&gt;% mutate(model = \"Abundance (NegBin)\")\n\n  all_models &lt;- bind_rows(m1_tidy, m2_tidy) %&gt;%\n    dplyr::select(model, term, estimate, std.error, statistic, p.value) %&gt;%\n    rename(\n      Model = model,\n      Term = term,\n      Estimate = estimate,\n      SE = std.error,\n      'Test Stat' = statistic,\n      'P-Value' = p.value\n    )\n\n  # Styled kable for model summary\n  summary_table &lt;- all_models %&gt;% \n    kable(format = \"html\", digits = 3, caption = \"Joint Model Output: Presence vs Abundance\") %&gt;% \n    kable_styling(\n      bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n      full_width = FALSE,\n      position = \"center\",\n      font_size = 14\n    ) %&gt;% \n    row_spec(0, bold = TRUE, color = \"white\", background = \"#A0185A\") %&gt;% \n    row_spec(1:nrow(all_models), color = \"black\", background = \"#FFC4EB\")\n\n  # Prediction grid\n  grid_data &lt;- expand_grid(\n    in_region = c(TRUE, FALSE),\n    northern_anchovy_z = seq(min(catch_plot$northern_anchovy_z), max(catch_plot$northern_anchovy_z), by = 1)\n  )\n\n  # Predictions\n  predict_pres &lt;- predict(m1, newdata = grid_data, type = \"link\", se.fit = TRUE)\n  predict_abu  &lt;- predict(m2, newdata = grid_data, type = \"link\", se.fit = TRUE)\n\n  pred_pres_result &lt;- grid_data %&gt;% \n    mutate(\n      fit_link = predict_pres$fit,\n      se = predict_pres$se.fit,\n      pred_tbs = plogis(fit_link),\n      lower = plogis(fit_link - 1.96*se),\n      upper = plogis(fit_link + 1.96*se)\n    )\n\n  pred_abu_result &lt;- grid_data %&gt;% \n    mutate(\n      fit_link = predict_abu$fit,\n      se = predict_abu$se.fit,\n      pred_tbs = exp(fit_link),\n      lower = exp(fit_link - 1.96*se),\n      upper = exp(fit_link + 1.96*se)\n    )\n\n  # Merge predictions\n  combined_pred &lt;- pred_pres_result %&gt;% \n    mutate(\n      expected_count = pred_tbs * pred_abu_result$pred_tbs,\n      lower_expected = lower * pred_abu_result$lower,\n      upper_expected = upper * pred_abu_result$upper\n    )\n\n  # Styled kables for predictions\n  pred_pres_table &lt;- pred_pres_result %&gt;% \n    kable(format = \"html\", digits = 3, caption = \"Presence Predictions\") %&gt;% \n    kable_styling(\n      bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n      full_width = FALSE,\n      position = \"center\",\n      font_size = 14\n    ) %&gt;% \n    row_spec(0, bold = TRUE, color = \"white\", background = \"#A0185A\") %&gt;% \n    row_spec(1:nrow(pred_pres_result), color = \"black\", background = \"#FFC4EB\") %&gt;% \n    scroll_box(width = \"800px\", height = \"300px\")\n\n  pred_abu_table &lt;- pred_abu_result %&gt;% \n    kable(format = \"html\", digits = 3, caption = \"Abundance Predictions\") %&gt;% \n    kable_styling(\n      bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n      full_width = FALSE,\n      position = \"center\",\n      font_size = 14\n    ) %&gt;% \n    row_spec(0, bold = TRUE, color = \"white\", background = \"#A0185A\") %&gt;% \n    row_spec(1:nrow(pred_abu_result), color = \"black\", background = \"#FFC4EB\") %&gt;% \n    scroll_box(width = \"800px\", height = \"300px\")\n\n  combined_table &lt;- combined_pred %&gt;% \n    kable(format = \"html\", digits = 3, caption = \"Expected Counts (Presence × Abundance)\") %&gt;% \n    kable_styling(\n      bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n      full_width = FALSE,\n      position = \"center\",\n      font_size = 14\n    ) %&gt;% \n    row_spec(0, bold = TRUE, color = \"white\", background = \"#A0185A\") %&gt;% \n    row_spec(1:nrow(combined_pred), color = \"black\", background = \"#FFC4EB\") %&gt;% \n    scroll_box(width = \"800px\", height = \"300px\")\n\n  # Plot\n  plot &lt;- ggplot(combined_pred, aes(northern_anchovy_z, expected_count)) +\n    facet_wrap(~in_region,\n               labeller = as_labeller(c(`TRUE` = \"In Region\", `FALSE` = \"Outside Region\"))) +\n    geom_line(color = '#A0185A') +\n    geom_ribbon(aes(ymin = lower_expected, ymax = upper_expected),\n                alpha = .3, fill = '#ABC798') +\n    labs(x = 'Northern Anchovy Z',\n         y = str_to_title(str_replace_all(species_name, \"_\", \" \"))) +\n    theme_clean()\n\n  return(list(\n    summary_table = summary_table,\n    pred_pres_table = pred_pres_table,\n    pred_abu_table = pred_abu_table,\n    combined_table = combined_table,\n    stage1_pred = pred_pres_result,\n    stage2_pred = pred_abu_result,\n    combined_pred = combined_pred,\n    plot = plot\n  ))\n}\n\n\n\n\nSimulate data\nBefore we use this model we will be simulating data in an attempt to see if the model is appropriate for our data.\n\n\nCode\nset.seed(42)\n\nn_sim &lt;- 1000\n\n# Predictor: standardized anchovy index\nnorthern_anchovy_z &lt;- rnorm(n_sim, mean = 0, sd = 1)\n\n# in_region alternates TRUE / FALSE / TRUE / FALSE ...\nin_region &lt;- rep(c(TRUE, FALSE), length.out = n_sim)\n\n# Logistic (presence/absence)\nbeta0_presence &lt;- -.5\nbeta1_presence &lt;-  1.2\n\n# Abundance (given present)\nbeta0_abundance &lt;- 0.7\nbeta1_abundance &lt;- 0.4\n\ntheta &lt;- 1.8  # NB dispersion\n\n# Probability of presence\np_presence &lt;- plogis(beta0_presence + beta1_presence * northern_anchovy_z)\n\n# Storage\npresence  &lt;- rep(0, n_sim)\nabundance &lt;- rep(0, n_sim)\n\nfor (i in 1:n_sim){\n\n  presence[i] &lt;- rbinom(1, 1, p_presence[i])\n\n  if(presence[i] == 1){\n\n    lambda_i &lt;- exp(beta0_abundance + beta1_abundance * northern_anchovy_z[i])\n\n    # truncated NB — no zeros allowed\n    repeat {\n      y &lt;- rnbinom(1, mu = lambda_i, size = theta)\n      if(y &gt; 0){\n        abundance[i] &lt;- y\n        break\n      }\n    }\n  }\n}\n\nsim_data &lt;- tibble(\n  northern_anchovy_z,\n  in_region,\n  presence,\n  abundance\n)\n\n\n\n\nSimulated Data model\nTo make sure the model returns the coefficients from the simulated data we can run our model on the dataframe of the model\n\nModel Simulated data\n\n\nCode\nm1 &lt;- glm(presence ~ northern_anchovy_z * in_region, \n          data = sim_data, \n          family = binomial(link = 'logit'))\n\nm2 &lt;- glm.nb(abundance ~ northern_anchovy_z * in_region, \n             data = sim_data)\n\nm1_tidy &lt;- tidy(m1)%&gt;% \n  mutate(model = \"Presence (Logit)\")\nm2_tidy &lt;- tidy(m2)%&gt;% \n  mutate(model = \"Abundance (NegBin)\")\n\n# combine and format\nall_models &lt;- bind_rows(m1_tidy, m2_tidy) %&gt;%\n  dplyr::select(model, term, estimate, std.error, statistic, p.value)%&gt;%\n  rename(\n    Model = model,\n    Term = term,\n    Estimate = estimate,\n    SE = std.error,\n    'Test Stat' = statistic,\n    'P-Value'   = p.value\n  ) \n\nkable(all_models, format = \"html\", digits = 3,\n      caption = \"Joint Model Output: Presence vs Abundance\")%&gt;%\n  kable_styling(\n    bootstrap_options = c(\"striped\", \"hover\", \"condensed\", \"responsive\"),\n    full_width = FALSE,\n    position   = \"center\",\n    font_size  = 14\n  ) %&gt;% \n  row_spec(0, bold = TRUE, color = \"white\", background = \"#A0185A\") %&gt;%  # header\n  row_spec(1:nrow(all_models), color = \"black\", background = \"#FFC4EB\")  # body rows\n\n\n\n\nJoint Model Output: Presence vs Abundance\n\n\nModel\nTerm\nEstimate\nSE\nTest Stat\nP-Value\n\n\n\n\nPresence (Logit)\n(Intercept)\n-0.463\n0.101\n-4.568\n0.000\n\n\nPresence (Logit)\nnorthern_anchovy_z\n1.022\n0.121\n8.427\n0.000\n\n\nPresence (Logit)\nin_regionTRUE\n-0.087\n0.146\n-0.599\n0.549\n\n\nPresence (Logit)\nnorthern_anchovy_z:in_regionTRUE\n0.116\n0.176\n0.659\n0.510\n\n\nAbundance (NegBin)\n(Intercept)\n-0.030\n0.079\n-0.376\n0.707\n\n\nAbundance (NegBin)\nnorthern_anchovy_z\n0.839\n0.081\n10.415\n0.000\n\n\nAbundance (NegBin)\nin_regionTRUE\n-0.099\n0.114\n-0.873\n0.382\n\n\nAbundance (NegBin)\nnorthern_anchovy_z:in_regionTRUE\n0.086\n0.117\n0.733\n0.464\n\n\n\n\n\n\n\n\n\nFunction Call: Central Bay\nThe top indicator for the Central Bay was the Speckled Sanddab so we can call the function for that species and region\n\n\nCode\nspeckled &lt;- predict_indicator(catch_clean, 'SSD', 'CENTRAL BAY')\n\n\nNow speckled is encoded with our model summaries, predictions, and plot. For this I will show all outputs, in later chunks I will bypass showing predictions\n\nModel Summary\n\n\nCode\nspeckled$summary_table\n\n\n\n\nJoint Model Output: Presence vs Abundance\n\n\nModel\nTerm\nEstimate\nSE\nTest Stat\nP-Value\n\n\n\n\nPresence (Logit)\n(Intercept)\n-1.556\n0.031\n-49.769\n0.000\n\n\nPresence (Logit)\nnorthern_anchovy_z\n-0.531\n0.087\n-6.127\n0.000\n\n\nPresence (Logit)\nin_regionTRUE\n1.089\n0.081\n13.490\n0.000\n\n\nPresence (Logit)\nnorthern_anchovy_z:in_regionTRUE\n0.160\n0.172\n0.931\n0.352\n\n\nAbundance (NegBin)\n(Intercept)\n1.965\n0.033\n59.284\n0.000\n\n\nAbundance (NegBin)\nnorthern_anchovy_z\n-0.058\n0.053\n-1.082\n0.279\n\n\nAbundance (NegBin)\nin_regionTRUE\n0.816\n0.077\n10.546\n0.000\n\n\nAbundance (NegBin)\nnorthern_anchovy_z:in_regionTRUE\n-0.101\n0.145\n-0.696\n0.487\n\n\n\n\n\n\n\n\nPresence Prediction\n\n\nCode\nspeckled$pred_pres_table\n\n\n\n\n\nPresence Predictions\n\n\nin_region\nnorthern_anchovy_z\nfit_link\nse\npred_tbs\nlower\nupper\n\n\n\n\nTRUE\n-0.273\n-0.367\n0.083\n0.409\n0.371\n0.449\n\n\nTRUE\n0.727\n-0.737\n0.134\n0.324\n0.269\n0.384\n\n\nTRUE\n1.727\n-1.107\n0.271\n0.248\n0.163\n0.360\n\n\nTRUE\n2.727\n-1.477\n0.417\n0.186\n0.092\n0.341\n\n\nTRUE\n3.727\n-1.847\n0.564\n0.136\n0.050\n0.323\n\n\nTRUE\n4.727\n-2.217\n0.712\n0.098\n0.026\n0.305\n\n\nTRUE\n5.727\n-2.587\n0.860\n0.070\n0.014\n0.289\n\n\nTRUE\n6.727\n-2.958\n1.009\n0.049\n0.007\n0.273\n\n\nTRUE\n7.727\n-3.328\n1.157\n0.035\n0.004\n0.257\n\n\nTRUE\n8.727\n-3.698\n1.306\n0.024\n0.002\n0.243\n\n\nTRUE\n9.727\n-4.068\n1.455\n0.017\n0.001\n0.228\n\n\nTRUE\n10.727\n-4.438\n1.603\n0.012\n0.001\n0.215\n\n\nTRUE\n11.727\n-4.808\n1.752\n0.008\n0.000\n0.202\n\n\nTRUE\n12.727\n-5.178\n1.901\n0.006\n0.000\n0.190\n\n\nTRUE\n13.727\n-5.549\n2.050\n0.004\n0.000\n0.178\n\n\nTRUE\n14.727\n-5.919\n2.199\n0.003\n0.000\n0.167\n\n\nTRUE\n15.727\n-6.289\n2.348\n0.002\n0.000\n0.156\n\n\nTRUE\n16.727\n-6.659\n2.497\n0.001\n0.000\n0.146\n\n\nTRUE\n17.727\n-7.029\n2.645\n0.001\n0.000\n0.137\n\n\nTRUE\n18.727\n-7.399\n2.794\n0.001\n0.000\n0.128\n\n\nTRUE\n19.727\n-7.770\n2.943\n0.000\n0.000\n0.119\n\n\nTRUE\n20.727\n-8.140\n3.092\n0.000\n0.000\n0.111\n\n\nTRUE\n21.727\n-8.510\n3.241\n0.000\n0.000\n0.104\n\n\nTRUE\n22.727\n-8.880\n3.390\n0.000\n0.000\n0.097\n\n\nTRUE\n23.727\n-9.250\n3.539\n0.000\n0.000\n0.090\n\n\nTRUE\n24.727\n-9.620\n3.688\n0.000\n0.000\n0.084\n\n\nTRUE\n25.727\n-9.990\n3.837\n0.000\n0.000\n0.078\n\n\nTRUE\n26.727\n-10.361\n3.986\n0.000\n0.000\n0.073\n\n\nTRUE\n27.727\n-10.731\n4.135\n0.000\n0.000\n0.067\n\n\nFALSE\n-0.273\n-1.412\n0.032\n0.196\n0.186\n0.206\n\n\nFALSE\n0.727\n-1.942\n0.080\n0.125\n0.109\n0.144\n\n\nFALSE\n1.727\n-2.473\n0.164\n0.078\n0.058\n0.104\n\n\nFALSE\n2.727\n-3.004\n0.249\n0.047\n0.030\n0.075\n\n\nFALSE\n3.727\n-3.534\n0.336\n0.028\n0.015\n0.053\n\n\nFALSE\n4.727\n-4.065\n0.422\n0.017\n0.007\n0.038\n\n\nFALSE\n5.727\n-4.595\n0.508\n0.010\n0.004\n0.027\n\n\nFALSE\n6.727\n-5.126\n0.595\n0.006\n0.002\n0.019\n\n\nFALSE\n7.727\n-5.657\n0.681\n0.003\n0.001\n0.013\n\n\nFALSE\n8.727\n-6.187\n0.768\n0.002\n0.000\n0.009\n\n\nFALSE\n9.727\n-6.718\n0.854\n0.001\n0.000\n0.006\n\n\nFALSE\n10.727\n-7.248\n0.941\n0.001\n0.000\n0.004\n\n\nFALSE\n11.727\n-7.779\n1.028\n0.000\n0.000\n0.003\n\n\nFALSE\n12.727\n-8.310\n1.114\n0.000\n0.000\n0.002\n\n\nFALSE\n13.727\n-8.840\n1.201\n0.000\n0.000\n0.002\n\n\nFALSE\n14.727\n-9.371\n1.287\n0.000\n0.000\n0.001\n\n\nFALSE\n15.727\n-9.901\n1.374\n0.000\n0.000\n0.001\n\n\nFALSE\n16.727\n-10.432\n1.460\n0.000\n0.000\n0.001\n\n\nFALSE\n17.727\n-10.963\n1.547\n0.000\n0.000\n0.000\n\n\nFALSE\n18.727\n-11.493\n1.634\n0.000\n0.000\n0.000\n\n\nFALSE\n19.727\n-12.024\n1.720\n0.000\n0.000\n0.000\n\n\nFALSE\n20.727\n-12.554\n1.807\n0.000\n0.000\n0.000\n\n\nFALSE\n21.727\n-13.085\n1.893\n0.000\n0.000\n0.000\n\n\nFALSE\n22.727\n-13.616\n1.980\n0.000\n0.000\n0.000\n\n\nFALSE\n23.727\n-14.146\n2.067\n0.000\n0.000\n0.000\n\n\nFALSE\n24.727\n-14.677\n2.153\n0.000\n0.000\n0.000\n\n\nFALSE\n25.727\n-15.207\n2.240\n0.000\n0.000\n0.000\n\n\nFALSE\n26.727\n-15.738\n2.326\n0.000\n0.000\n0.000\n\n\nFALSE\n27.727\n-16.269\n2.413\n0.000\n0.000\n0.000\n\n\n\n\n\n\n\n\n\nAbundance Prediction\n\n\nCode\nspeckled$pred_abu_table\n\n\n\n\n\nAbundance Predictions\n\n\nin_region\nnorthern_anchovy_z\nfit_link\nse\npred_tbs\nlower\nupper\n\n\n\n\nTRUE\n-0.273\n2.825\n0.076\n16.854\n14.533\n19.545\n\n\nTRUE\n0.727\n2.666\n0.126\n14.380\n11.227\n18.419\n\n\nTRUE\n1.727\n2.507\n0.250\n12.270\n7.512\n20.043\n\n\nTRUE\n2.727\n2.348\n0.382\n10.469\n4.952\n22.134\n\n\nTRUE\n3.727\n2.190\n0.515\n8.933\n3.253\n24.531\n\n\nTRUE\n4.727\n2.031\n0.649\n7.622\n2.134\n27.223\n\n\nTRUE\n5.727\n1.872\n0.784\n6.504\n1.399\n30.231\n\n\nTRUE\n6.727\n1.714\n0.919\n5.549\n0.917\n33.583\n\n\nTRUE\n7.727\n1.555\n1.053\n4.735\n0.601\n37.316\n\n\nTRUE\n8.727\n1.396\n1.188\n4.040\n0.394\n41.470\n\n\nTRUE\n9.727\n1.238\n1.323\n3.447\n0.258\n46.091\n\n\nTRUE\n10.727\n1.079\n1.458\n2.941\n0.169\n51.231\n\n\nTRUE\n11.727\n0.920\n1.593\n2.510\n0.111\n56.947\n\n\nTRUE\n12.727\n0.761\n1.728\n2.141\n0.072\n63.304\n\n\nTRUE\n13.727\n0.603\n1.863\n1.827\n0.047\n70.373\n\n\nTRUE\n14.727\n0.444\n1.998\n1.559\n0.031\n78.234\n\n\nTRUE\n15.727\n0.285\n2.133\n1.330\n0.020\n86.974\n\n\nTRUE\n16.727\n0.127\n2.268\n1.135\n0.013\n96.692\n\n\nTRUE\n17.727\n-0.032\n2.403\n0.968\n0.009\n107.498\n\n\nTRUE\n18.727\n-0.191\n2.538\n0.826\n0.006\n119.513\n\n\nTRUE\n19.727\n-0.349\n2.673\n0.705\n0.004\n132.873\n\n\nTRUE\n20.727\n-0.508\n2.808\n0.602\n0.002\n147.727\n\n\nTRUE\n21.727\n-0.667\n2.943\n0.513\n0.002\n164.243\n\n\nTRUE\n22.727\n-0.826\n3.078\n0.438\n0.001\n182.607\n\n\nTRUE\n23.727\n-0.984\n3.213\n0.374\n0.001\n203.025\n\n\nTRUE\n24.727\n-1.143\n3.348\n0.319\n0.000\n225.727\n\n\nTRUE\n25.727\n-1.302\n3.483\n0.272\n0.000\n250.969\n\n\nTRUE\n26.727\n-1.460\n3.618\n0.232\n0.000\n279.035\n\n\nTRUE\n27.727\n-1.619\n3.753\n0.198\n0.000\n310.241\n\n\nFALSE\n-0.273\n1.981\n0.033\n7.251\n6.797\n7.736\n\n\nFALSE\n0.727\n1.923\n0.056\n6.845\n6.127\n7.646\n\n\nFALSE\n1.727\n1.866\n0.105\n6.461\n5.262\n7.934\n\n\nFALSE\n2.727\n1.808\n0.156\n6.099\n4.490\n8.286\n\n\nFALSE\n3.727\n1.750\n0.209\n5.757\n3.824\n8.669\n\n\nFALSE\n4.727\n1.693\n0.262\n5.435\n3.255\n9.075\n\n\nFALSE\n5.727\n1.635\n0.315\n5.130\n2.770\n9.503\n\n\nFALSE\n6.727\n1.577\n0.368\n4.843\n2.356\n9.954\n\n\nFALSE\n7.727\n1.520\n0.421\n4.571\n2.004\n10.427\n\n\nFALSE\n8.727\n1.462\n0.474\n4.315\n1.705\n10.924\n\n\nFALSE\n9.727\n1.404\n0.527\n4.073\n1.450\n11.445\n\n\nFALSE\n10.727\n1.347\n0.580\n3.845\n1.233\n11.991\n\n\nFALSE\n11.727\n1.289\n0.633\n3.630\n1.049\n12.564\n\n\nFALSE\n12.727\n1.231\n0.687\n3.426\n0.892\n13.164\n\n\nFALSE\n13.727\n1.174\n0.740\n3.234\n0.758\n13.793\n\n\nFALSE\n14.727\n1.116\n0.793\n3.053\n0.645\n14.453\n\n\nFALSE\n15.727\n1.058\n0.846\n2.882\n0.548\n15.144\n\n\nFALSE\n16.727\n1.001\n0.900\n2.721\n0.466\n15.868\n\n\nFALSE\n17.727\n0.943\n0.953\n2.568\n0.397\n16.627\n\n\nFALSE\n18.727\n0.885\n1.006\n2.424\n0.337\n17.423\n\n\nFALSE\n19.727\n0.828\n1.060\n2.288\n0.287\n18.257\n\n\nFALSE\n20.727\n0.770\n1.113\n2.160\n0.244\n19.131\n\n\nFALSE\n21.727\n0.712\n1.166\n2.039\n0.207\n20.047\n\n\nFALSE\n22.727\n0.655\n1.219\n1.925\n0.176\n21.006\n\n\nFALSE\n23.727\n0.597\n1.273\n1.817\n0.150\n22.012\n\n\nFALSE\n24.727\n0.539\n1.326\n1.715\n0.128\n23.066\n\n\nFALSE\n25.727\n0.482\n1.379\n1.619\n0.108\n24.170\n\n\nFALSE\n26.727\n0.424\n1.433\n1.528\n0.092\n25.328\n\n\nFALSE\n27.727\n0.366\n1.486\n1.443\n0.078\n26.541\n\n\n\n\n\n\n\n\n\nCombined Prediction\n\n\nCode\nspeckled$combined_table\n\n\n\n\n\nExpected Counts (Presence × Abundance)\n\n\nin_region\nnorthern_anchovy_z\nfit_link\nse\npred_tbs\nlower\nupper\nexpected_count\nlower_expected\nupper_expected\n\n\n\n\nTRUE\n-0.273\n-0.367\n0.083\n0.409\n0.371\n0.449\n6.900\n5.387\n8.780\n\n\nTRUE\n0.727\n-0.737\n0.134\n0.324\n0.269\n0.384\n4.655\n3.019\n7.070\n\n\nTRUE\n1.727\n-1.107\n0.271\n0.248\n0.163\n0.360\n3.049\n1.222\n7.217\n\n\nTRUE\n2.727\n-1.477\n0.417\n0.186\n0.092\n0.341\n1.946\n0.454\n7.540\n\n\nTRUE\n3.727\n-1.847\n0.564\n0.136\n0.050\n0.323\n1.217\n0.161\n7.913\n\n\nTRUE\n4.727\n-2.217\n0.712\n0.098\n0.026\n0.305\n0.749\n0.056\n8.311\n\n\nTRUE\n5.727\n-2.587\n0.860\n0.070\n0.014\n0.289\n0.455\n0.019\n8.727\n\n\nTRUE\n6.727\n-2.958\n1.009\n0.049\n0.007\n0.273\n0.274\n0.007\n9.159\n\n\nTRUE\n7.727\n-3.328\n1.157\n0.035\n0.004\n0.257\n0.164\n0.002\n9.604\n\n\nTRUE\n8.727\n-3.698\n1.306\n0.024\n0.002\n0.243\n0.098\n0.001\n10.061\n\n\nTRUE\n9.727\n-4.068\n1.455\n0.017\n0.001\n0.228\n0.058\n0.000\n10.530\n\n\nTRUE\n10.727\n-4.438\n1.603\n0.012\n0.001\n0.215\n0.034\n0.000\n11.010\n\n\nTRUE\n11.727\n-4.808\n1.752\n0.008\n0.000\n0.202\n0.020\n0.000\n11.501\n\n\nTRUE\n12.727\n-5.178\n1.901\n0.006\n0.000\n0.190\n0.012\n0.000\n12.004\n\n\nTRUE\n13.727\n-5.549\n2.050\n0.004\n0.000\n0.178\n0.007\n0.000\n12.517\n\n\nTRUE\n14.727\n-5.919\n2.199\n0.003\n0.000\n0.167\n0.004\n0.000\n13.041\n\n\nTRUE\n15.727\n-6.289\n2.348\n0.002\n0.000\n0.156\n0.002\n0.000\n13.576\n\n\nTRUE\n16.727\n-6.659\n2.497\n0.001\n0.000\n0.146\n0.001\n0.000\n14.122\n\n\nTRUE\n17.727\n-7.029\n2.645\n0.001\n0.000\n0.137\n0.001\n0.000\n14.680\n\n\nTRUE\n18.727\n-7.399\n2.794\n0.001\n0.000\n0.128\n0.001\n0.000\n15.248\n\n\nTRUE\n19.727\n-7.770\n2.943\n0.000\n0.000\n0.119\n0.000\n0.000\n15.828\n\n\nTRUE\n20.727\n-8.140\n3.092\n0.000\n0.000\n0.111\n0.000\n0.000\n16.420\n\n\nTRUE\n21.727\n-8.510\n3.241\n0.000\n0.000\n0.104\n0.000\n0.000\n17.024\n\n\nTRUE\n22.727\n-8.880\n3.390\n0.000\n0.000\n0.097\n0.000\n0.000\n17.640\n\n\nTRUE\n23.727\n-9.250\n3.539\n0.000\n0.000\n0.090\n0.000\n0.000\n18.269\n\n\nTRUE\n24.727\n-9.620\n3.688\n0.000\n0.000\n0.084\n0.000\n0.000\n18.912\n\n\nTRUE\n25.727\n-9.990\n3.837\n0.000\n0.000\n0.078\n0.000\n0.000\n19.567\n\n\nTRUE\n26.727\n-10.361\n3.986\n0.000\n0.000\n0.073\n0.000\n0.000\n20.237\n\n\nTRUE\n27.727\n-10.731\n4.135\n0.000\n0.000\n0.067\n0.000\n0.000\n20.922\n\n\nFALSE\n-0.273\n-1.412\n0.032\n0.196\n0.186\n0.206\n1.421\n1.267\n1.593\n\n\nFALSE\n0.727\n-1.942\n0.080\n0.125\n0.109\n0.144\n0.858\n0.669\n1.098\n\n\nFALSE\n1.727\n-2.473\n0.164\n0.078\n0.058\n0.104\n0.503\n0.303\n0.826\n\n\nFALSE\n2.727\n-3.004\n0.249\n0.047\n0.030\n0.075\n0.288\n0.133\n0.620\n\n\nFALSE\n3.727\n-3.534\n0.336\n0.028\n0.015\n0.053\n0.163\n0.057\n0.462\n\n\nFALSE\n4.727\n-4.065\n0.422\n0.017\n0.007\n0.038\n0.092\n0.024\n0.343\n\n\nFALSE\n5.727\n-4.595\n0.508\n0.010\n0.004\n0.027\n0.051\n0.010\n0.253\n\n\nFALSE\n6.727\n-5.126\n0.595\n0.006\n0.002\n0.019\n0.029\n0.004\n0.186\n\n\nFALSE\n7.727\n-5.657\n0.681\n0.003\n0.001\n0.013\n0.016\n0.002\n0.137\n\n\nFALSE\n8.727\n-6.187\n0.768\n0.002\n0.000\n0.009\n0.009\n0.001\n0.100\n\n\nFALSE\n9.727\n-6.718\n0.854\n0.001\n0.000\n0.006\n0.005\n0.000\n0.073\n\n\nFALSE\n10.727\n-7.248\n0.941\n0.001\n0.000\n0.004\n0.003\n0.000\n0.054\n\n\nFALSE\n11.727\n-7.779\n1.028\n0.000\n0.000\n0.003\n0.002\n0.000\n0.039\n\n\nFALSE\n12.727\n-8.310\n1.114\n0.000\n0.000\n0.002\n0.001\n0.000\n0.029\n\n\nFALSE\n13.727\n-8.840\n1.201\n0.000\n0.000\n0.002\n0.000\n0.000\n0.021\n\n\nFALSE\n14.727\n-9.371\n1.287\n0.000\n0.000\n0.001\n0.000\n0.000\n0.015\n\n\nFALSE\n15.727\n-9.901\n1.374\n0.000\n0.000\n0.001\n0.000\n0.000\n0.011\n\n\nFALSE\n16.727\n-10.432\n1.460\n0.000\n0.000\n0.001\n0.000\n0.000\n0.008\n\n\nFALSE\n17.727\n-10.963\n1.547\n0.000\n0.000\n0.000\n0.000\n0.000\n0.006\n\n\nFALSE\n18.727\n-11.493\n1.634\n0.000\n0.000\n0.000\n0.000\n0.000\n0.004\n\n\nFALSE\n19.727\n-12.024\n1.720\n0.000\n0.000\n0.000\n0.000\n0.000\n0.003\n\n\nFALSE\n20.727\n-12.554\n1.807\n0.000\n0.000\n0.000\n0.000\n0.000\n0.002\n\n\nFALSE\n21.727\n-13.085\n1.893\n0.000\n0.000\n0.000\n0.000\n0.000\n0.002\n\n\nFALSE\n22.727\n-13.616\n1.980\n0.000\n0.000\n0.000\n0.000\n0.000\n0.001\n\n\nFALSE\n23.727\n-14.146\n2.067\n0.000\n0.000\n0.000\n0.000\n0.000\n0.001\n\n\nFALSE\n24.727\n-14.677\n2.153\n0.000\n0.000\n0.000\n0.000\n0.000\n0.001\n\n\nFALSE\n25.727\n-15.207\n2.240\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nFALSE\n26.727\n-15.738\n2.326\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nFALSE\n27.727\n-16.269\n2.413\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\n\n\n\n\n\n\n\nSpeckled plot\n\n\nCode\nspeckled$plot\n\n\n\n\n\n\n\n\n\n\n\nDiscussion: Speckled Sanddab\nBased on the function we can see significance in presence of Anchovy and the region in both presence and abundance. This indicates that the presence of Anchovy comes at the cost of presence of Sanddabs. This model does not seem to fit incredibly well when looking at the plot, which can be seen by the flat lines and giant confidence intervals.\n\n\n\nFunction Call: San Pablo Bay\n\n\nCode\nbat_ray &lt;- predict_indicator(catch_clean, 'BR', 'SAN PABLO BAY')\n\n\n\nModel Summary\n\n\nCode\nbat_ray$summary_table\n\n\n\n\nJoint Model Output: Presence vs Abundance\n\n\nModel\nTerm\nEstimate\nSE\nTest Stat\nP-Value\n\n\n\n\nPresence (Logit)\n(Intercept)\n2.598\n0.043\n59.788\n0.000\n\n\nPresence (Logit)\nnorthern_anchovy_z\n-0.801\n0.034\n-23.834\n0.000\n\n\nPresence (Logit)\nin_regionTRUE\n-1.980\n0.960\n-2.063\n0.039\n\n\nPresence (Logit)\nnorthern_anchovy_z:in_regionTRUE\n1.476\n0.932\n1.584\n0.113\n\n\nAbundance (NegBin)\n(Intercept)\n4.321\n0.018\n236.057\n0.000\n\n\nAbundance (NegBin)\nnorthern_anchovy_z\n-0.223\n0.022\n-10.216\n0.000\n\n\nAbundance (NegBin)\nin_regionTRUE\n-3.409\n0.917\n-3.719\n0.000\n\n\nAbundance (NegBin)\nnorthern_anchovy_z:in_regionTRUE\n0.276\n0.461\n0.599\n0.549\n\n\n\n\n\n\n\n\nBat Ray Plot\n\n\nCode\nbat_ray$plot\n\n\n\n\n\n\n\n\n\n\n\nDiscussion: Bat Ray\nBased on the summary table, we can see significance of both presence and abundance in relation to Northern Anchovy. Interestingly the presence is barely insignificant while abundance is significant in region, indicating that this species is an indicator based more on abundance.\n\n\n\nFunction Call: South Bay\n\n\nCode\nca_tonguefish &lt;- predict_indicator(catch_clean, 'CT', 'SOUTH BAY')\n\n\n\nModel Summary\n\n\nCode\nca_tonguefish$summary_table\n\n\n\n\nJoint Model Output: Presence vs Abundance\n\n\nModel\nTerm\nEstimate\nSE\nTest Stat\nP-Value\n\n\n\n\nPresence (Logit)\n(Intercept)\n4.655\n1.087\n4.281\n0.000\n\n\nPresence (Logit)\nnorthern_anchovy_z\n-16.415\n3.855\n-4.258\n0.000\n\n\nPresence (Logit)\nin_regionTRUE\n-0.948\n1.090\n-0.870\n0.384\n\n\nPresence (Logit)\nnorthern_anchovy_z:in_regionTRUE\n16.228\n3.855\n4.210\n0.000\n\n\nAbundance (NegBin)\n(Intercept)\n3.871\n0.348\n11.140\n0.000\n\n\nAbundance (NegBin)\nnorthern_anchovy_z\n-3.820\n1.985\n-1.925\n0.054\n\n\nAbundance (NegBin)\nin_regionTRUE\n0.463\n0.348\n1.330\n0.183\n\n\nAbundance (NegBin)\nnorthern_anchovy_z:in_regionTRUE\n3.689\n1.985\n1.859\n0.063\n\n\n\n\n\n\n\n\nTonguefish Plot\n\n\nCode\nca_tonguefish$plot\n\n\n\n\n\n\n\n\n\n\n\nDiscussion: California Tonguefish\nIn my opinion this is the most interesting interaction. Presence in region, based on Northern Anchovy, and the interaction between the two are all significant. This is the only case in the analysis where any interaction is significant. When looking at abundance, both Anchovies and the interaction between them and in_region are minimally insignificant. When looking at the plot we see the best looking curve in the plot of within region. All this is super interesting in the context that in recent years there have been very few catches of Tonguefish, which indicates some sort of temporal skew.\n\n\n\nFunction Call: Suisun Bay\n\n\nCode\nbass &lt;- predict_indicator(catch_clean, 'SB', 'SUISUN BAY')\n\n\nWarning: glm.fit: fitted probabilities numerically 0 or 1 occurred\n\n\nWarning in predict.lm(object, newdata, se.fit, scale = residual.scale, type =\nif (type == : prediction from rank-deficient fit; attr(*, \"non-estim\") has\ndoubtful cases\n\n\n\nPresence Summary\n\n\nCode\nbass$summary_table\n\n\n\n\nJoint Model Output: Presence vs Abundance\n\n\nModel\nTerm\nEstimate\nSE\nTest Stat\nP-Value\n\n\n\n\nPresence (Logit)\n(Intercept)\n-3.647\n0.121\n-30.195\n0.000\n\n\nPresence (Logit)\nnorthern_anchovy_z\n-2.844\n0.496\n-5.735\n0.000\n\n\nPresence (Logit)\nin_regionTRUE\n-2499.678\n183385.798\n-0.014\n0.989\n\n\nPresence (Logit)\nnorthern_anchovy_z:in_regionTRUE\n-9032.834\n657659.105\n-0.014\n0.989\n\n\nAbundance (NegBin)\n(Intercept)\n0.330\n0.093\n3.553\n0.000\n\n\nAbundance (NegBin)\nnorthern_anchovy_z\n-0.521\n0.333\n-1.563\n0.118\n\n\nAbundance (NegBin)\nin_regionTRUE\n1.410\n0.089\n15.896\n0.000\n\n\n\n\n\n\n\n\nBass Plot\n\n\nCode\nbass$plot\n\n\n\n\n\n\n\n\n\n\n\nDiscussion: Striped Bass\nIf Tonguefish was our best model, this would be our worst. When fitting the model we get the warning: prediction from rank-deficient fit; attr(*, “non-estim”) has doubtful cases. This indicates that the function is having trouble fitting the model to this data. This means that the summary and plot end up being generally unreliable. This was a big surprise to me as I expected Striped Bass to show an intense correlation, as they like less salty water when they pass through the bay (as infants and juveniles).\n\n\n\nFinal Discussion\nDespite the effort, this analysis indicates that there is no real correlation between these indicator species and Northern Anchovy populations. In the future it may be possible to fit specific models to specific fish, and alter the models based on the fish species. Furthermore the integration of actual water quality variables such as temperature and salinity may yield more significance and representation within the data.\n\n\n\n\n\nReferences\n\nBritannica, The Editors of Encyclopaedia. n.d. “San Francisco Bay.” https://www.britannica.com/place/San-Francisco-Bay. https://www.britannica.com/place/San-Francisco-Bay.\n\n\nConservation, San Francisco Bay, and Development Commission. 2002. “San Francisco Bay Ecology and Related Habitats.” Staff Report –. San Francisco Bay Conservation; Development Commission (BCDC); https://www.bcdc.ca.gov/wp-content/uploads/sites/354/2023/09/San-Francisco-Bay-Ecology-And-Related-Habitats-PDF.pdf. https://www.bcdc.ca.gov/wp-content/uploads/sites/354/2023/09/San-Francisco-Bay-Ecology-And-Related-Habitats-PDF.pdf.\n\n\nCouncil, California Ocean Protection. 2022. “Harmful Algal Bloom in San Francisco Bay Results in Aquatic Mortality, Fish Kills.” https://opc.ca.gov/2022/09/harmful-algal-bloom/. https://opc.ca.gov/2022/09/harmful-algal-bloom/.\n\n\nInstitute, Marine Science. n.d. “Marine Science Institute — San Francisco Bay.” Accessed December 4, 2025. https://www.sfbaymsi.org/.\n\n\nPartnership, San Francisco Estuary. n.d. “About the Estuary.” https://www.sfestuary.org/our-estuary/about-the-estuary/. https://www.sfestuary.org/our-estuary/about-the-estuary/.\n\n\nWooldridge, Griffin. 2020. “Silhouette of Bridge During Sunset.” https://www.pexels.com/photo/silhouette-of-bridge-during-sunset-3654847/. https://www.pexels.com/photo/silhouette-of-bridge-during-sunset-3654847/.\n\nCitationBibTeX citation:@online{vitale2025,\n  author = {Vitale, Peter},\n  title = {San {Fransisco} {Bay} {Catch} {Dynamics}},\n  date = {2025-12-03},\n  url = {https://petervitale910.github.io/},\n  langid = {en}\n}\nFor attribution, please cite this work as:\nVitale, Peter. 2025. “San Fransisco Bay Catch Dynamics.”\nDecember 3, 2025. https://petervitale910.github.io/."
  },
  {
    "objectID": "posts/extreme_weather_events/index.html",
    "href": "posts/extreme_weather_events/index.html",
    "title": "Extreme Weather Events",
    "section": "",
    "text": "This is where the body of my blog post begins! I’m going to add a footnote here 1 Here’s and inline footnote2\nCiting reference (Shanny-Csik 2022)\nlets cite a paper using the DOI (Gaynor et al. 2022)"
  },
  {
    "objectID": "posts/extreme_weather_events/index.html#footnotes",
    "href": "posts/extreme_weather_events/index.html#footnotes",
    "title": "Extreme Weather Events",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHere is some additional context that might be helpful↩︎\nhere’s my inline note↩︎"
  },
  {
    "objectID": "posts/palisades_eaton_ejscreen/index.html",
    "href": "posts/palisades_eaton_ejscreen/index.html",
    "title": "Visualizing the 2025 California Wildfires",
    "section": "",
    "text": "Guillen (2025)"
  },
  {
    "objectID": "posts/palisades_eaton_ejscreen/index.html#about-this-project",
    "href": "posts/palisades_eaton_ejscreen/index.html#about-this-project",
    "title": "Visualizing the 2025 California Wildfires",
    "section": "About this project",
    "text": "About this project\nIn this project we will be using true and false color imagery to examine the impacts of two fires which struck the Los Angeles area in early 2025.\n\nHighlights:\n\nExtracting color bands from xarray\nMapping using true and false color imagery\nOverlaying fire perimiters to see effect of fires\n\n\n\nBackground information\nThe Palisades and Eaton fires sparked within hours of each other on January 7th 2025. Due to arid conditions and the Santa Ana winds these fires quickly grew out of control, ultimately burning a combined 40,000 acres (VanAuken 2025). The fires led to significant damage and economic loss, estimated between $135 billion and $150 billion (“Media Advisory: AccuWeather Increases Estimate of Total Damage and Economic Loss as Catastrophic Wildfires Continue to Ravage the Los Angeles Area” 2025). In this project we will examine the total land area covered by the fires as well as examine socioeconomic factors to interpret the communities affected by, as well as the long lasting effects of the fires.\n\n\nAbout the data:\n\nPalisades and Eaton fire perimeters\nThese contain dissolved fire perimeters/boundaries for Eaton and Palisades fires, with boundary polygons dissolved for each fire to create a single fire burn perimeter. Access given by the County of Los Angeles (“Palisades and Eaton Dissolved Fire Perimeters (2025)” 2025)\n\n\nNetcdf landsat data\nLandsat C2 L2 from Microsoft’s Planetary Computer is a globally available, multi-decadal archive of atmospherically corrected, analysis-ready Landsat imagery. Surface reflectance for multispectral bands and derived land surface temperature from thermal bands are provided in cloud-optimized GeoTIFFs, accessible via a STAC API. Accordingly, it is primarily used for long-term environmental monitoring, spectral studies, and thermal remote sensing, and is designed for scalable, cloud-native remote sensing workflows (U.S. Geological Survey 2025)\n\n\n\n1. Import packages and datasets\n\n\nCode\nimport pandas as pd\nimport geopandas as gpd \nimport matplotlib.pyplot as plt\nimport os \nimport xarray as xr\nimport rioxarray as rio\nimport numpy as np \nfrom matplotlib_scalebar.scalebar import ScaleBar\nimport contextily as ctx\n\n\n\n\n\n2. Fire perimeter data exploration\nHere we import the perimeter data files and do some exploration.\nI am going to import both perimeters and then look at the CRS, or coordinate reference system. This allows us to map all datasets using the same projection.\n\n\nCode\nfp = os.path.join('data','Eaton_Perimeter_20250121','Eaton_Perimeter_20250121.shp')\neaton_perimeter = gpd.read_file(fp)\n\n\n\n\nCode\nfp = os.path.join('data','Palisades_Perimeter_20250121','Palisades_Perimeter_20250121.shp')\npalisades_perimeter = gpd.read_file(fp)\n\n\n\n\nCode\n# Now we can look at the crs's and do some exploration \npalisades_perimeter.crs\n\n\n&lt;Projected CRS: EPSG:3857&gt;\nName: WGS 84 / Pseudo-Mercator\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: World between 85.06°S and 85.06°N.\n- bounds: (-180.0, -85.06, 180.0, 85.06)\nCoordinate Operation:\n- name: Popular Visualisation Pseudo-Mercator\n- method: Popular Visualisation Pseudo Mercator\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\n\n\nCode\neaton_perimeter.crs\n\n\n&lt;Projected CRS: EPSG:3857&gt;\nName: WGS 84 / Pseudo-Mercator\nAxis Info [cartesian]:\n- X[east]: Easting (metre)\n- Y[north]: Northing (metre)\nArea of Use:\n- name: World between 85.06°S and 85.06°N.\n- bounds: (-180.0, -85.06, 180.0, 85.06)\nCoordinate Operation:\n- name: Popular Visualisation Pseudo-Mercator\n- method: Popular Visualisation Pseudo Mercator\nDatum: World Geodetic System 1984 ensemble\n- Ellipsoid: WGS 84\n- Prime Meridian: Greenwich\n\n\nWe know we want to merge these datasets at some point, so it is important to check if the column names match in the two perimeters\n\n\nCode\n# Lets compare the column names to make sure they match \n\nprint(f' It is {eaton_perimeter.columns == palisades_perimeter.columns} that the column names match')\n\n\n It is [ True  True  True  True  True] that he column names match\n\n\n\n\nCode\n# Thats great we only need to look at one of the dataframes columns \n\nprint(' The column names of the data frames are', eaton_perimeter.columns)\n\n\n The column names of the data frames are Index(['OBJECTID', 'type', 'Shape__Are', 'Shape__Len', 'geometry'], dtype='object')\n\n\nSummary: From the preliminary exploration both the Palisades and Eaton datasets are in ESPG:3857, which is a projected coordinate system. Both have the same column names which will make analysis and merging easier.\n\n\n3. NetCDF data import and exploration\nHere we will import and explore the Landsat data using xr.open_dataset().\n\n\nCode\nnetcdf = xr.open_dataset('data/landsat8-2025-02-23-palisades-eaton.nc')\n\n\n\n\nCode\nnetcdf\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 78MB\nDimensions:      (y: 1418, x: 2742)\nCoordinates:\n  * y            (y) float64 11kB 3.799e+06 3.799e+06 ... 3.757e+06 3.757e+06\n  * x            (x) float64 22kB 3.344e+05 3.344e+05 ... 4.166e+05 4.166e+05\n    time         datetime64[ns] 8B ...\nData variables:\n    red          (y, x) float32 16MB ...\n    green        (y, x) float32 16MB ...\n    blue         (y, x) float32 16MB ...\n    nir08        (y, x) float32 16MB ...\n    swir22       (y, x) float32 16MB ...\n    spatial_ref  int64 8B ...xarray.DatasetDimensions:y: 1418x: 2742Coordinates: (3)y(y)float643.799e+06 3.799e+06 ... 3.757e+06units :metreresolution :-30.0crs :EPSG:32611axis :Ylong_name :y coordinate of projectionstandard_name :projection_y_coordinatearray([3799050., 3799020., 3798990., ..., 3756600., 3756570., 3756540.])x(x)float643.344e+05 3.344e+05 ... 4.166e+05units :metreresolution :30.0crs :EPSG:32611axis :Xlong_name :x coordinate of projectionstandard_name :projection_x_coordinatearray([334410., 334440., 334470., ..., 416580., 416610., 416640.])time()datetime64[ns]...[1 values with dtype=datetime64[ns]]Data variables: (6)red(y, x)float32...grid_mapping :spatial_ref[3888156 values with dtype=float32]green(y, x)float32...grid_mapping :spatial_ref[3888156 values with dtype=float32]blue(y, x)float32...grid_mapping :spatial_ref[3888156 values with dtype=float32]nir08(y, x)float32...grid_mapping :spatial_ref[3888156 values with dtype=float32]swir22(y, x)float32...grid_mapping :spatial_ref[3888156 values with dtype=float32]spatial_ref()int64...crs_wkt :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]semi_major_axis :6378137.0semi_minor_axis :6356752.314245179inverse_flattening :298.257223563reference_ellipsoid_name :WGS 84longitude_of_prime_meridian :0.0prime_meridian_name :Greenwichgeographic_crs_name :WGS 84horizontal_datum_name :World Geodetic System 1984projected_crs_name :WGS 84 / UTM zone 11Ngrid_mapping_name :transverse_mercatorlatitude_of_projection_origin :0.0longitude_of_central_meridian :-117.0false_easting :500000.0false_northing :0.0scale_factor_at_central_meridian :0.9996spatial_ref :PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]GeoTransform :334395.0 30.0 0.0 3799065.0 0.0 -30.0[1 values with dtype=int64]Indexes: (2)yPandasIndexPandasIndex(Index([3799050.0, 3799020.0, 3798990.0, 3798960.0, 3798930.0, 3798900.0,\n       3798870.0, 3798840.0, 3798810.0, 3798780.0,\n       ...\n       3756810.0, 3756780.0, 3756750.0, 3756720.0, 3756690.0, 3756660.0,\n       3756630.0, 3756600.0, 3756570.0, 3756540.0],\n      dtype='float64', name='y', length=1418))xPandasIndexPandasIndex(Index([334410.0, 334440.0, 334470.0, 334500.0, 334530.0, 334560.0, 334590.0,\n       334620.0, 334650.0, 334680.0,\n       ...\n       416370.0, 416400.0, 416430.0, 416460.0, 416490.0, 416520.0, 416550.0,\n       416580.0, 416610.0, 416640.0],\n      dtype='float64', name='x', length=2742))Attributes: (0)\n\n\nThis xarray has 1418 y dimensions and 2742 x dimensions. The coordinates are x, y, and time which are are float64, float64, and datetime64 types (respectively). The variables are red, green, blue, near infared and short wave infared light bands as well as a spatial reference. The bands are in float32 while the spatial_ref is an int64, this shouldn’t be an issue going further - however as the analysis continues it may become an issue.\n\n\n4. Restoring geospatial information\nWe need to use rio.crs to print what is the CRS of this dataset, which will help us plot the light bands onto the same area as the fire perimeters.\n\n\nCode\nprint(f'The xarray has the crs: {netcdf.rio.crs}')\n\n\nThe xarray has the crs: None\n\n\nOh no! Theres no crs meaning that it will be harder to plot, however there actually is! It’s just encoded in the spatial_ref variable.\n\n\nCode\nprint(f' The actual crs of the xarray is: {netcdf.spatial_ref.crs_wkt}')\n\n\n The actual crs of the xarray is: PROJCS[\"WGS 84 / UTM zone 11N\",GEOGCS[\"WGS 84\",DATUM[\"WGS_1984\",SPHEROID[\"WGS 84\",6378137,298.257223563,AUTHORITY[\"EPSG\",\"7030\"]],AUTHORITY[\"EPSG\",\"6326\"]],PRIMEM[\"Greenwich\",0,AUTHORITY[\"EPSG\",\"8901\"]],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]],AUTHORITY[\"EPSG\",\"4326\"]],PROJECTION[\"Transverse_Mercator\"],PARAMETER[\"latitude_of_origin\",0],PARAMETER[\"central_meridian\",-117],PARAMETER[\"scale_factor\",0.9996],PARAMETER[\"false_easting\",500000],PARAMETER[\"false_northing\",0],UNIT[\"metre\",1,AUTHORITY[\"EPSG\",\"9001\"]],AXIS[\"Easting\",EAST],AXIS[\"Northing\",NORTH],AUTHORITY[\"EPSG\",\"32611\"]]\n\n\nOh wow thats big! Lets make it so that crs is the crs for the dataset\n\n\nCode\nnetcdf = netcdf.rio.write_crs(netcdf.spatial_ref.crs_wkt) # Need to write_crs due to being an xarrray\n\n\n\n\nCode\nprint(f'The xarray now has the crs: {netcdf.rio.crs}')\n\n\nThe xarray now has the crs: EPSG:32611\n\n\n\n\n5. True color image\nA true color image takes the light bands collected by landsat and plots the colors visible to the human eye. This is how the ground would look if we were sitting on the satelite\nTo create a true color plot we need to:\n\nIdentify which bands have nan values.\nSelect the red, green, and blue variables (in that order) of the xarray.Dataset holding the Landsat data,\nConvert it to a numpy.array using the to_array() method, and then\nUse .plot.imshow() to create an RGB image with the data.\nAdjust the scale used for plotting the bands to get a true color image.\nUse the .fillna() method for xarray.Datasets to substitute any nan values in the Landsat data for zero.\nCreate a true color image that gets plotted without warnings.\n\n\n\nCode\nprint(f'The red band has {np.isnan(netcdf.red).sum().item()} na values')\nprint(f'The green band has {np.isnan(netcdf.green).sum().item()} na values')\nprint(f'The blue band has {np.isnan(netcdf.blue).sum().item()} na values')\n\n\nThe red band has 0 na values\nThe green band has 1 na values\nThe blue band has 109 na values\n\n\n\n\nCode\nnetcdf[['red', 'green', 'blue']].fillna(0).to_array().plot.imshow(robust = True) # Fillna and robust = true are the fix for the two problems\n\n\n\n\n\n\n\n\n\nYou can sort of see the fire damage, however it isnt as aparant as the false color image.\n\n\n6. False color image\nFalse color images plot short wave infared, near infared, and red bands. By assigning infrared bands to visible colors, these images highlight vegetation health, burn severity, and the extent of fire scars. This approach helps researchers and land managers assess recovery efforts, identify high-risk areas, and plan restoration strategies (“Assignment 4: Thomas Fire — MEDS-EDS-220 Course” 2025)\n\n\nCode\n# This plotting code is very similar to the other, but we are selecting bands\nnetcdf[['swir22', 'nir08', 'red']].to_array().plot.imshow(robust = True) # Note! No Na's are present\n\n\n\n\n\n\n\n\n\nThe red areas are burn scars from the fires, and to see them better we can plot the fire perimeters on top.\n\n\n7. Map\nHere we map the fire perimeters onto the false color image. Before we plot we need to make sure that the crs matches\n\n\nCode\n# Before we plot we need to ensure we are in the same crs\npalisades_perimeter = palisades_perimeter.to_crs(netcdf.rio.crs)\n\n\neaton_perimeter = eaton_perimeter.to_crs(netcdf.rio.crs)\n\n\n\n\nCode\n \n\nfig, ax = plt.subplots(1, 1, figsize = (14,12)) # Set a size for our figure\n\nnetcdf[['swir22', 'nir08', 'red']].to_array().plot.imshow(robust = True, ax = ax) # Choose false color bands\n\neaton_perimeter.plot(ax = ax, color = 'none', edgecolor = 'red') # Plot Eaton fire perimeter in red\n\npalisades_perimeter.plot(ax = ax, color = 'none', edgecolor = 'red') # And the Palisade perimeter\n\n\nplt.suptitle('False Color image of Palisades and Eaton fires in Santa Barbara', \n             fontsize=16, \n             y = .77) # This y was a lot of guess and checking \nplt.title(\"Plot of SWIR, NIR, and RED light bands\", \n          fontsize=12, \n          y=1.01) # Title defaults inside the plot and I want it just above, hence 1.01\n\n\n\nplt.figtext(x = .2, # The position of the figtext, In units of 0-1 for x and y \n            y = .46,\n            s = 'Palisades Fire Perimeter',\n            color = 'black',\n            bbox ={'facecolor':'grey',  # Add a box around text for legibility \n                   'alpha':1, 'pad':5}) \nplt.figtext(x = .67, \n            y = .63, \n            s= 'Eaton Fire Perimeter',\n            color = 'black',\n           bbox ={'facecolor':'grey', \n                   'alpha':1, 'pad':5})\n\nax.add_artist(ScaleBar(1, dimension=\"si-length\", units=\"m\", location=\"lower left\")) # Add a scale bar on the lower left\n\nax.axis('off') # Turn Axes off\n\nplt.show() # Show plot only \n\n\n\n\n\n\n\n\n\nShort-wave infrared (SWIR) was mapped to the red channel, near-infrared (NIR) to green, and the red band to blue. This false-color composite highlights post-fire effects from the January 2025 Palisades–Eaton fires. Burned areas appear as bright orange to deep red, while the fire perimeter is outlined in red for clarity, with the fire name next to the perimeter. As you can see some of the fire perimeter still contains some vegitation, thanks to our brave firefighters.\n\n\n8. Intersection with environmental justice\nIn this and the following sections we will be accessing data from the California Environmental Justice Index (EJI), and plotting census count information in the context of the fire perimeters.\nWe begin by importing the EJI. (Centers for Disease Control and Prevention and Agency for Toxic Substances and Disease Registry 2021)\n\n\nCode\neji_ca = gpd.read_file('/Users/petervitale/Desktop/MEDS/Career/petervitale910.github.io/posts/palisades_eaton_ejscreen/data/EJI_2024_California /EJI_2024_California.gdb')\n\n\nThe EJI has a number of socioeconomic factors along with geometries of where the census was taken. These include:\n\nPercentage of housing units that are renter occupied: E_RENTER\nPercentage of persons who are unisured: E_UNINSUR\n65+: E_AGE65\nproportion of greenspace: E_PARK\n\n\n\n9. Polygon intersection\nTo find where social variables intersect our fire perimeters we can use polygon intersection, where we examine where the shape of the census tracts intersect with the shape of the fire perimeter.\n\n\nCode\n# From previous exploration I know the crs' do not match \n# Spatially join EJI with palisades\npali_eji = gpd.sjoin(eji_ca.to_crs(palisades_perimeter.crs), palisades_perimeter) \n\nfig, ax = plt.subplots(figsize = (11,5))\nax.axis('off')\npali_eji.plot('TRACTCE',\n              ax = ax)\n\npalisades_perimeter.plot(ax = ax,\n                    color = 'none',\n                    edgecolor = 'red',\n                    linewidth = 1.5)\n\n\n\n\n\n\n\n\n\nPolygon intersection includes the entire census tracts that are touching the fire, see orange. This problem becomes more aparent when we plot the Eaton fire.\n\n\nCode\n# Eaton fire\n\n# From previous exploration i know the crs do not match \n# Spatially join EJI with palisades\neaton_eji = gpd.sjoin(eji_ca.to_crs(eaton_perimeter.crs), eaton_perimeter) \n\nfig, ax = plt.subplots(figsize = (11,5))\nax.axis('off')\neaton_eji.plot('TRACTCE',\n              ax = ax)\n\neaton_perimeter.plot(ax = ax,\n                    color = 'none',\n                    edgecolor = 'red',\n                    linewidth = 1.5)\n\n\n\n\n\n\n\n\n\nAs you can see a large census tract is completely included, despite a comparably small portion of the tract having been effected by the fire.\n\n\n10. Polygon clipping\nInstead of polygon intersection we will be using polygon clipping. If you think of cookies, polygon intersection is like the dalgona cookies from squid games. The shape is almost cut out, however the larger area is still aparent. Polygon clipping is more like using cookie cutter to only choose the area from fire perimeter, not the entire census.\nFor future plotting we are going to make new, clipped variables.\n\n\nCode\neji_ca = eji_ca.to_crs(palisades_perimeter.crs)\nclip_eji_pali = gpd.clip(eji_ca, palisades_perimeter)\nclip_eji_eaton = gpd.clip(eji_ca, eaton_perimeter)\n\n\nAs you can see the clipped plots show the exact areas of the census tracts which were in the fire perimeters.\n\n\nCode\nclip_eji_pali.plot('TRACTCE')\n\n\n\n\n\n\n\n\n\n\n\nCode\nclip_eji_eaton.plot('TRACTCE')\n\n\n\n\n\n\n\n\n\n\n\n11. Visualize fire perimeters with a basemap\nUsing the package ctx we can add a base map to contextualize the fire areas within the greater Los Angeles Area.\n\n\nCode\nfig, ax = plt.subplots(1, 1, figsize=(14, 12))\nax.ticklabel_format(style='plain')\n\n\n# 1. Reproject everything to EPSG:3857\nclip_eji_pali_3857      = clip_eji_pali.to_crs(epsg=3857)\nclip_eji_eaton_3857     = clip_eji_eaton.to_crs(epsg=3857)\npalisades_perimeter_3857 = palisades_perimeter.to_crs(epsg=3857)\neaton_perimeter_3857     = eaton_perimeter.to_crs(epsg=3857)\n\n# 2. Plot layers\nclip_eji_pali_3857.plot(\n    ax=ax, facecolor='red', alpha=0.6, edgecolor='none'\n)\nclip_eji_eaton_3857.plot(\n    ax=ax, facecolor='blue', alpha=0.4, edgecolor='none'\n)\n\npalisades_perimeter_3857.plot(\n    ax=ax, color='none', edgecolor='black', linewidth=2\n)\neaton_perimeter_3857.plot(\n    ax=ax, color='none', edgecolor='purple', linewidth=2\n)\n\n# 3. Add basemap last\nctx.add_basemap(ax=ax, source=ctx.providers.OpenStreetMap.Mapnik)\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nThis plot turns highlights the neighborhoods which were effected, as well as showing just how close to more densly populated areas the fires got.\n\n\n12. Mapping socioecomic factors\nFor this section I chose to examine the percentage of the census tracts which were renters. I chose this because, following the fires, renters faced issues with: - Loss of homes - Rent increases (double to triple the price) - Landlords trying to push out long-term renters who pay lower rents to make way for displaced fire victims who have more money to spend - Paying out of pocket to clean and fix partially damaged rental space (CBS Los Angeles 2025)\nThese issues compound the already devistating fire and reduce quality of life for renters.\nTo plot this I used the percentage of census tracts which are renters.\n\n\nCode\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 12))\n\n# UPDATE WITH YOU EJI VARIABLE FROM STEP 1\neji_variable = 'E_RENTER'\n\n# Find common min/max for legend range\nvmin = min(clip_eji_pali[eji_variable].min(), clip_eji_eaton[eji_variable].min())\nvmax = max(clip_eji_pali[eji_variable].max(), clip_eji_eaton[eji_variable].max())\n\n# Plot census tracts within Palisades perimeter\nclip_eji_pali.plot(\n    column= eji_variable,\n    vmin=vmin, vmax=vmax,\n    legend=False,\n    ax=ax1,\n)\nax1.set_title('Palisades Fire')\nax1.axis('off')\n\n# Plot census tracts within Eaton perimeter\nclip_eji_eaton.plot(\n    column=eji_variable,\n    vmin=vmin, vmax=vmax,\n    legend=False,\n    ax=ax2,\n)\nax2.set_title('Eaton Fire')\nax2.axis('off')\n\n# Add overall title\nfig.suptitle('Renter occupied buildings in Palisades and Eaton Fires')\n\n# Add shared colorbar at the bottom\nsm = plt.cm.ScalarMappable( norm=plt.Normalize(vmin=vmin, vmax=vmax))\ncbar_ax = fig.add_axes([0.25, 0.08, 0.5, 0.02])  # [left, bottom, width, height]\ncbar = fig.colorbar(sm, cax=cbar_ax, orientation='horizontal')\ncbar.set_label('Percent Renters')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nFrom the map you can see that the Palisades fire affected more renters, with a large area of close to 50% renters being found at the lower left of the perimeter (Malibu). While this is an affluent area, it has seen some of the highest level of post-fire price gouging (FOX 11 Los Angeles 2025). This could alienate those who have historically lived in the communities to move elsewhere, shifting the social and demographic makeup of these areas."
  },
  {
    "objectID": "posts/aquaculture_and_eezs/index.html",
    "href": "posts/aquaculture_and_eezs/index.html",
    "title": "Aquaculture and EEZ’s",
    "section": "",
    "text": "DESCRIPTION OF EEZ”S AND WHY I LIKE THIS\nCode\npacman::p_load('tidyverse', \n               'sf', \n               'here',\n               'tmap', \n               'kableExtra',\n               'patchwork',\n               'stars',\n               'terra')"
  },
  {
    "objectID": "posts/aquaculture_and_eezs/index.html#data-import",
    "href": "posts/aquaculture_and_eezs/index.html#data-import",
    "title": "Aquaculture and EEZ’s",
    "section": "Data import",
    "text": "Data import\n\nSurface temperature from: [@noaa_crw_sst31]\n\n\nCode\nsst_2008 &lt;- rast(here('posts', 'aquaculture_and_eezs','data',\n                      'average_annual_sst_2008.tif')) \n\nsst_2009 &lt;- rast(here('posts', 'aquaculture_and_eezs','data',\n                      'average_annual_sst_2009.tif'))\nsst_2010 &lt;- rast(here('posts', 'aquaculture_and_eezs', 'data',\n                      'average_annual_sst_2010.tif'))\nsst_2011 &lt;- rast(here('posts', 'aquaculture_and_eezs','data',\n                      'average_annual_sst_2011.tif'))\nsst_2012 &lt;- rast(here('posts', 'aquaculture_and_eezs', 'data',\n                      'average_annual_sst_2012.tif'))\n\n\n\n\nBathymetry\nFrom: [@gebcobathymetriccompilationgroup20252025]\n\n\nCode\nbathy &lt;- rast(here('posts', 'aquaculture_and_eezs', 'data','depth.tif')) %&gt;% \n  project(\"EPSG:4326\") # Coerce into correct crs \n\n\n\n\nExclusive Economic Zones\nFrom: [@marine_regions_eez_v12]\n\n\nCode\neez &lt;- st_read(here('posts', 'aquaculture_and_eezs','data',\n                    'wc_regions_clean.shp'), quiet = TRUE) %&gt;% \n  st_transform(\"EPSG:4326\") # STARS OBJECT"
  },
  {
    "objectID": "posts/aquaculture_and_eezs/index.html#surface-temperature-mean",
    "href": "posts/aquaculture_and_eezs/index.html#surface-temperature-mean",
    "title": "Aquaculture and EEZ’s",
    "section": "Surface temperature mean",
    "text": "Surface temperature mean\n\n\nCode\n# Stacked raster\nstacked_sst &lt;- c(sst_2008, sst_2009, sst_2010, sst_2011, sst_2012) %&gt;% # Here we stack our temperatures and then transform crs\n  project(\"EPSG:4326\") \n\n# Take mean of stacked raster and transform from Kelvin to Celsius\nmean_sst &lt;- mean(stacked_sst) - 273.15"
  },
  {
    "objectID": "posts/aquaculture_and_eezs/index.html#bathymetry-1",
    "href": "posts/aquaculture_and_eezs/index.html#bathymetry-1",
    "title": "Aquaculture and EEZ’s",
    "section": "Bathymetry",
    "text": "Bathymetry\n\n\nCode\n# First we need to assure this data is in the same crs as sst\ndepth_projected &lt;- project(bathy, mean_sst) # Project the crs of mean sst on depth \n\ncrs(depth_projected) == crs(mean_sst)\n\n\n[1] TRUE\n\n\nCode\n# We are going to crop the depth raster to the eez\ndepth_cropped &lt;- crop(depth_projected, mean_sst)\n\n# And resample to make sure our pixel sizes match \ndepth_resampled &lt;- resample(depth_projected, mean_sst)"
  },
  {
    "objectID": "posts/aquaculture_and_eezs/index.html#oyster-reclassification",
    "href": "posts/aquaculture_and_eezs/index.html#oyster-reclassification",
    "title": "Aquaculture and EEZ’s",
    "section": "Oyster Reclassification",
    "text": "Oyster Reclassification\nWe need to reclassify for oysters, which enjoy depth between -70 meters and 0 meters and temperatures between 11 and 30 degrees celcius\n\n\nCode\nrcl_depth &lt;- matrix(c(-Inf, -70, 0, # Anything below 70 m becomes a 0\n                    -70, 0, 1, # Between 70 and 0 becomes 1\n                    0, Inf, 0), # And above 0 becomes a 0\n                    nrow = 3, \n                    byrow = TRUE)\n\nrcl_temp &lt;- matrix(c(-Inf, 11, 0, # Below 11 degrees becomes 0\n                     11, 30, 1, # Between 11 and 30 becomes 1\n                     30, Inf, 0), # Above 30 becomes 0\n                   nrow =3,\n                   byrow = TRUE)\n# Apply those matrices\ndepth_rcl &lt;- classify(depth_resampled, rcl_depth) \n\nsst_rcl &lt;- classify(mean_sst, rcl_temp)\n\n\nWe want to keep where both sst and depth equal one, so we can multiply the two rasters.\n\n\nCode\nsuitable_cells &lt;- sst_rcl * depth_rcl\n\n# And make all 0's NA\nsuitable_cells[suitable_cells == 0] &lt;- NA\n\n# Finally, since we only have ones, change that to suitable\nnames(suitable_cells) &lt;- 'Suitable'\n\n\n\n\nCode\n# Now we want to see the area of the suitable cells, which we can get by multiplying suitable_cells and the cellSize of each cell\narea_raster &lt;- suitable_cells * cellSize(suitable_cells, unit = 'km')  \n\n\n\n\nCode\n# Here we extract where that area touches our eez\narea_extracted &lt;- terra::extract(area_raster, \n                                 eez, \n                                 touches = TRUE) %&gt;%  \n  group_by(ID) %&gt;% # Then we group_by and summarise the total suitable area per eez region\n  summarise(suitable_area = sum(Suitable, na.rm = TRUE)) %&gt;% \n  mutate(rgn = eez$rgn)\n\n\n\n\nCode\n# Lastly we want to left join to preserve the area information of each eez region\nregion_suitable_area &lt;- left_join(x = eez,\n                                  y = area_extracted, \n                                  by = \"rgn\") %&gt;% \n  select(-ID) # Get rid of ID column\n\n\n\nMap\nNow we have our final mapping data frame and can build our map\n\n\nCode\ntm_basemap(\"Esri.WorldTopoMap\")+# I found this basemap fit the best\ntm_shape(region_suitable_area)+\n  tm_polygons(fill = 'suitable_area',\n              fill.scale = tm_scale(values = c('#E1DABD', # Add my color palette \n                                              '#ABC798',\n                                              '#FFC4EB',\n                                              '#E6983F',\n                                              '#A0185A'),\n                                    breaks = c(0, \n                                               800, # Specify breaks \n                                               1600,\n                                               2400, \n                                               3200,\n                                               4000)),\n              fill.legend = tm_legend( '        Total \\nSuitable area (km)'))+ # The blank space makes 'Total' centered\n  tm_title(text = paste('Suitable area for farming Oysters in West Coast EEZ'), \n           position = tm_pos_out(\"center\", \"top\", pos.h = \"center\"))+ # Add title and position in center\n  tm_layout(component.autoscale = FALSE)+ # Autoscale makes our title tiny so we turn it off\n  tm_graticules(alpha = .5)+ # Add graticules (lighter)\n  tm_text('rgn', size = .7)+ # This adds the region name on each polygon centroid\ntm_shape(suitable_cells)+ # I want to add the visual representation of where the suitable area is \n  tm_raster(col  =  'Suitable',\n             col.scale =  tm_scale(values = '#90AFDA', # This color is also part of my palette\n            labels = 'Suitable Area'), # In place of a title  we will be specific with our legend text\n            col.legend = tm_legend(title = \"\")) # No need for a legend title with a single raster variable\n\n\n\n\n\n\n\n\n\n\n\nTable\nI also want to be able to see a table of our exact suitable area in each region so we can use kable\n\n\nCode\nregion_suitable_area %&gt;% \n  st_drop_geometry() %&gt;% # The only way to lose geometry\n  select(-rgn_key, -rgn_id, -area_m2) %&gt;% # Drop unnecesary columns\nkbl(col.names = c('Region', 'Total Area (Km2)', 'Suitable Area (Km2)')) %&gt;%  # Rename the columns in our table\n  kable_classic(full_width = F, # This is my favorite type of table\n                html_font = \"Cambria\") %&gt;% \n  footnote(number = paste('EEZ region suitable area for farming Oysters')) # Add a footnote\n\n\n\n\n\nRegion\nTotal Area (Km2)\nSuitable Area (Km2)\n\n\n\n\nOregon\n179994.06\n1147.883\n\n\nNorthern California\n164378.81\n194.126\n\n\nCentral California\n202738.33\n3673.514\n\n\nSouthern California\n206860.78\n3259.485\n\n\nWashington\n66898.31\n2524.804\n\n\n\n1 EEZ region suitable area for farming Oysters"
  },
  {
    "objectID": "posts/aquaculture_and_eezs/index.html#function",
    "href": "posts/aquaculture_and_eezs/index.html#function",
    "title": "Aquaculture and EEZ’s",
    "section": "Function",
    "text": "Function\nNow that I have my workflow solidified I can turn it into a function, so with just the species name it can output a map.\n\n\nCode\n#' Map EEZ\n#' Make a map of a suitable area of a species in west coast EEZ's\n#' @param species \n#' The name of your species, MUST be wrapped AND Uppercase eg: ('Pacific Oyster')\n#' @returnsA list containing:\n#'   - $map   : tmap object\n#'   - $table : kable table\n#' @export\n#' @examples\n#' \nmap_eez &lt;- function(species){\n\n  species_dict &lt;- list(\n  \n  # -----------------------------\n  # SHELLFISH\n  # -----------------------------\n  \n  \"Pacific Oyster\" = list(\n    t_lwr = 11, t_upr = 30,\n    d_lower = 70, d_upr = 0\n  ),\n\n  \"Olympia Oyster\" = list(\n    t_lwr = 8,  t_upr = 20,\n    d_lower = 40, d_upr = 0\n  ),\n\n  \"Geoduck\" = list(\n    t_lwr = 5, t_upr = 18,\n    d_lower = 100, d_upr = 5\n  ),\n\n  \"Razor Clam\" = list(\n    t_lwr = 5, t_upr = 17,\n    d_lower = 20, d_upr = 0\n  ),\n\n  \"Blue Mussel\" = list(\n    t_lwr = 5, t_upr = 20,\n    d_lower = 30, d_upr = 0\n  ),\n\n  \"Mediterranean Mussel\" = list(\n    t_lwr = 8, t_upr = 26,\n    d_lower = 40, d_upr = 0\n  ),\n\n  \"Scallop\" = list(\n    t_lwr = 8, t_upr = 20,\n    d_lower = 50, d_upr = 0\n  ),\n  \n  # -----------------------------\n  # KELP + SEAWEEDS\n  # -----------------------------\n  \n  \"Bull Kelp\" = list(\n    t_lwr = 10, t_upr = 18,\n    d_lower = 40, d_upr = 0\n  ),\n  \n  \"Giant Kelp\" = list(\n    t_lwr = 6,  t_upr = 20,\n    d_lower = 30, d_upr = 0\n  ),\n  \n  \"Sugar Kelp\" = list(\n    t_lwr = -2, t_upr = 15,\n    d_lower = 50, d_upr = 1\n  ),\n  \n  \"Dulse\" = list(\n    t_lwr = 5,  t_upr = 15,\n    d_lower = 10, d_upr = 0\n  ),\n  \n  \"Sea Lettuce\" = list(\n    t_lwr = 5,  t_upr = 25,\n    d_lower = 10, d_upr = 0\n  ),\n  \n  \"Winged Kelp\" = list(\n    t_lwr = 2, t_upr = 15,\n    d_lower = 40, d_upr = 0\n  ),\n\n  \"Pyropia (Nori)\" = list(\n    t_lwr = 5,  t_upr = 15,\n    d_lower = 10, d_upr = 0\n  ),\n  \n  # -----------------------------\n  # ECHINODERMS (URCHINS)\n  # -----------------------------\n  \n  \"Green Sea Urchin\" = list(\n    t_lwr = 0, t_upr = 15,\n    d_lower = 200, d_upr = 0\n  ),\n\n  \"Red Sea Urchin\" = list(\n    t_lwr = 5, t_upr = 20,\n    d_lower = 100, d_upr = 3\n  ),\n  \n  # -----------------------------\n  # FINFISH\n  # -----------------------------\n\n  \"Chinook Salmon\" = list(\n    t_lwr = 8,  t_upr = 14,\n    d_lower = 200, d_upr = 0\n  ),\n\n  \"Coho Salmon\" = list(\n    t_lwr = 7, t_upr = 14,\n    d_lower = 150, d_upr = 0\n  ),\n\n  \"Steelhead Trout\" = list(\n    t_lwr = 7, t_upr = 17,\n    d_lower = 100, d_upr = 0\n  ),\n\n  \"Pacific Halibut\" = list(\n    t_lwr = 3,  t_upr = 12,\n    d_lower = 450, d_upr = 20\n  ),\n\n  \"Sablefish\" = list(\n    t_lwr = 4,  t_upr = 12,\n    d_lower = 1500, d_upr = 50\n  ),\n\n  \"Pacific Sardine\" = list(\n    t_lwr = 12, t_upr = 20,\n    d_lower = 0, d_upr = 50\n  ),\n\n  \"Northern Anchovy\" = list(\n    t_lwr = 12, t_upr = 20,\n    d_lower = 0, d_upr = 50\n  ),\n  \n  # -----------------------------\n  # CRUSTACEANS\n  # -----------------------------\n\n  \"Dungeness Crab\" = list(\n    t_lwr = 7, t_upr = 18,\n    d_lower = 100, d_upr = 0\n  )\n)\n\n# Extract parameters from the dictionary\nparams &lt;- species_dict[[species]]\nif (species == \"list\") {\n  return(names(species_dict))\n}\n\nif (is.null(params)) stop(\"Species not found in dictionary. Check spelling.\")\n\n# Access individual values\nt_lwr &lt;- params$t_lwr\nt_upr &lt;- params$t_upr\nd_lower &lt;- params$d_lower\nd_upr   &lt;- params$d_upr\n\n# Reclassification matrices\nrcl_depth &lt;- matrix(c(-Inf, -d_lower, 0, # Use variables like values\n                      -d_lower, -d_upr, 1,\n                      -d_upr, Inf, 0), \n                    nrow = 3, \n                    byrow = TRUE)\n\nrcl_temp &lt;- matrix(c(-Inf, t_lwr, 0,\n                     t_lwr, t_upr, 1,\n                     t_upr, Inf, 0), \n                   nrow =3,\n                   byrow = TRUE)\n\n# Reclassify \ndepth_rcl &lt;- classify(depth_resampled, rcl_depth)\n\nsst_rcl &lt;- classify(mean_sst, rcl_temp)\n\n# Calculate suitable cells\nsuitable_cells &lt;- sst_rcl * depth_rcl\n\nsuitable_cells[suitable_cells == 0] &lt;- NA\n\nnames(suitable_cells) &lt;- 'Suitable'\n\n# Calculate area of suitable cells\narea_raster &lt;- suitable_cells * cellSize(suitable_cells, unit = 'km')\n\n# Extract suitable areas \narea_extracted &lt;- terra::extract(area_raster, \n                                 eez, \n                                 touches = TRUE) %&gt;%  \n  group_by(ID) %&gt;% \n  summarise(suitable_area = sum(Suitable, na.rm = TRUE)) %&gt;% \n  mutate(rgn = eez$rgn)\n\n# Create geodf with suitable area and eez area\nregion_suitable_area &lt;- left_join(x = eez,\n                                  y = area_extracted, \n                                  by = \"rgn\") %&gt;% \n  select(-ID)\n\n\n# Create map\nmap &lt;- tm_basemap(\"Esri.WorldTopoMap\")+\n  tm_shape(region_suitable_area)+\n  tm_polygons(fill = 'suitable_area',\n              fill.scale = tm_scale(values = c('#E1DABD',\n                                               '#ABC798',\n                                               '#FFC4EB',\n                                               '#E6983F',\n                                               '#A0185A'),\n                                    n = 5), # Set 5 breaks\n              fill.legend = tm_legend( '        Total \\nSuitable area (km)'))+\n  tm_title(text = paste('Suitable area for farming', species, 'in West Coast EEZ'), position = tm_pos_out(\"center\", \"top\", pos.h = \"center\"))+ # Paste allows us to manipulate the title of the plot\n  tm_layout(component.autoscale = FALSE)+\n  tm_graticules(alpha = .5)+\n  tm_text('rgn', size = .7)+\ntm_shape(suitable_cells)+\n  tm_raster(col  =  'Suitable',\n             col.scale =  tm_scale(values = '#90AFDA', \n            labels = 'Suitable Area'),\n            col.legend = tm_legend(title = \"\"))\n\n# Create table\ntable &lt;- region_suitable_area %&gt;% \n  st_drop_geometry() %&gt;% \n  select(-rgn_key, -rgn_id, -area_m2) %&gt;% \nkbl(col.names = c('Region', \n                  'Total Area (Km2)', \n                  'Suitable Area (Km2)')) %&gt;% \n  kable_classic(full_width = F, \n                html_font = \"Cambria\") %&gt;% \n  footnote(number = paste('EEZ region suitable area for farming', species)) # Paste again\n\nreturn(list( # Make a list of our map and table so they can be called with a buck\n    map = map, \n    table = table\n  ))\n}\n\n\nNow we can call the function for any species in our species list\nTo know species options you can run map_eez(‘list’)\n\nmap_eez('list')\n\n [1] \"Pacific Oyster\"       \"Olympia Oyster\"       \"Geoduck\"             \n [4] \"Razor Clam\"           \"Blue Mussel\"          \"Mediterranean Mussel\"\n [7] \"Scallop\"              \"Bull Kelp\"            \"Giant Kelp\"          \n[10] \"Sugar Kelp\"           \"Dulse\"                \"Sea Lettuce\"         \n[13] \"Winged Kelp\"          \"Pyropia (Nori)\"       \"Green Sea Urchin\"    \n[16] \"Red Sea Urchin\"       \"Chinook Salmon\"       \"Coho Salmon\"         \n[19] \"Steelhead Trout\"      \"Pacific Halibut\"      \"Sablefish\"           \n[22] \"Pacific Sardine\"      \"Northern Anchovy\"     \"Dungeness Crab\"      \n\n\nNow we can call the function with any species from the list we find interesting, in this case Bull Kelp AND WHY\n\nbull_kelp &lt;- map_eez('Bull Kelp')\n\nCall the map\n\nbull_kelp$map\n\n\n\n\n\n\n\n\nCall the table\n\nbull_kelp$table\n\n\n\n\nRegion\nTotal Area (Km2)\nSuitable Area (Km2)\n\n\n\n\nOregon\n179994.06\n1065.055\n\n\nNorthern California\n164378.81\n1023.031\n\n\nCentral California\n202738.33\n1674.401\n\n\nSouthern California\n206860.78\n1622.344\n\n\nWashington\n66898.31\n3246.458\n\n\n\n1 EEZ region suitable area for farming Bull Kelp"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Peter Vitale",
    "section": "",
    "text": "I’m a marine biologist with a passion for ocean life, data visualization, and science communication. I studied Marine Biology at UC Santa Cruz and have worked in environmental education, field research, and data analysis. I enjoy finding creative ways to connect people with the natural world and make environmental data more engaging and accessible."
  },
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Blog Posts",
    "section": "",
    "text": "San Fransisco Bay Catch Dynamics\n\n\n\nMEDS\n\nR\n\nStatistics\n\n\n\nExamining Northern Anchovies ability to predict indicator species\n\n\n\nPeter Vitale\n\n\nDec 3, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizing the 2025 California Wildfires\n\n\n\nMEDS\n\nGeospatial\n\nPython\n\n\n\nPlotting true and false color images with landsat data.\n\n\n\nPeter Vitale\n\n\nDec 1, 2025\n\n\n\n\n\n\n\n\n\n\n\nAquaculture and EEZ’s\n\n\n\nMEDS\n\nR\n\nGeospatial\n\n\n\nExamining where in the North Pacific Economic Exclusive Zone is best for aquaculture of different species\n\n\n\nPeter Vitale\n\n\nNov 28, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nExtreme Weather Events\n\n\n\nMEDS\n\nR\n\nGeospatial\n\n\n\nExamining blackouts in Houston,TX following a 2021 storm\n\n\n\nPeter Vitale\n\n\nNov 12, 2025\n\n\n\n\n\n\nNo matching items"
  }
]